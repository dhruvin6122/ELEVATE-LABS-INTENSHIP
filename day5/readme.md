# âœ… Task 5: Decision Tree and Random Forest

## ðŸ“Œ Dataset
- Used the **Heart Disease Dataset** from Kaggle  
  Link: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset

## ðŸ›  Tools Used
- Python
- Scikit-learn
- Pandas, Matplotlib, Seaborn

## ðŸ§  What I Did
1. Trained a **Decision Tree Classifier**
2. **Visualized** the tree structure
3. Checked **overfitting** by changing the tree depth
4. Trained a **Random Forest Classifier**
5. Compared both models using **accuracy and cross-validation**
6. Plotted **feature importances**

## ðŸ“Š Accuracy Results
- Decision Tree: ~88%
- Random Forest: ~98% (Better performance)

## âœ… Conclusion
- Random Forest gave better accuracy and generalization
- Feature importance helped in understanding key columns


